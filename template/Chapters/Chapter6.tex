% Chapter 6

\chapter{Conclusion} % Main chapter title

\label{Chapter6} %

%---Abstract 

\section{Abstract}

%---Conclusion 

\section{Conclusion}

The hype over deep learning shows no signs of slowing down. With access to largers datasets, researchers are experimenting with different architecture and the trends are generally towards deeper networks with an increasing number of parameters \citep{ddl}. Training such complex models remains a challenging task to be solved. This makes it increasingly important to leverage hardware accelerators that benefit from the inherent parallelism in the training process of neural networks. FPGAs offer a lot of advantages as opposed to other hardware accelerators. For example, pipeline parallelism and irregular forms of concurrency can be well exploited.

In this work, we made use of Intel's OpenCL SDK to build a framework for training deep neural networks. We highlighted a custom development workflow to make development using OpenCL faster and more efficient. We also build the main operators that are the basic blocks for modern neural networks on FPGAs. By using the Deep500 library, we were also able to extend the benefits of this framework to support Open Source ONNX models and allow for building kernels that perform both inference and backpropagation. We have also benchmarked different implementations of the main operators, and performed integration testing and proof of correctness of the implementation. 

The framework is still a long way from being done and a lot of work can be done to extend it. For now it serves as a proof of concept, provides the right toolset, and lays the foundation for more optimizations and operator support.

Modern implementations with lower precision have proven to work with little sacrifice on the accuracy of models, so this remains as future work to be experimented. It is challenging to port lower precision to OpenCL as fixed point types are not currently supported by the languages. However, they can still by using integer operations and bit-masking techniques. 




%----------------------------------------------------------------------------------------
